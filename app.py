import pandas as pd
import streamlit as st

from model import KNK


@st.cache_data
def get_data(f, queries):
    st.write("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤...")
    knk_creator = KNK(queries_list=queries)
    df_id = pd.read_csv("./materials/df_id_comp.csv")
    df_id["–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è"] = df_id["–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è"].apply(lambda x: x.strip())
    st.write("–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ.")
    st.write("–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –ö–ù–ö...")
    knk_df, new_df, full_char_list = knk_creator.create(f)
    st.write("–ì–æ—Ç–æ–≤–æ!")
    return knk_df, new_df, full_char_list, df_id


queries = ["–Ω–∞–≤—ã–∫–∏", "–∑–Ω–∞–Ω–∏—è", "–∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏", "–¥–æ–ª–∂–Ω–æ—Å—Ç–∏", "Soft Skills"]

st.title("–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ñ–∏–ª—è –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π üíº")
file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–ª–∂–Ω–æ—Å—Ç–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é", type="docx")

if file:
    with st.status("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞..."):
        knk_df, new_df, full_char_list, df_id = get_data(file, queries)
    if knk_df is not None:
        st.header("–î–æ–ª–∂–Ω–æ—Å—Ç—å")
        df_position = knk_df[knk_df.columns[:3]].iloc[[0]]
        st.dataframe(df_position)

        soft_skills = [
            item for item in knk_df["–°–æ—Ñ—Ç-—Å–∫–∏–ª–ª—ã"].dropna().values if len(item) > 0
        ]
        if len(soft_skills) != 0:
            st.header("–°–æ—Ñ—Ç-—Å–∫–∏–ª–ª—ã")
            s = ""
            for skill in soft_skills:
                s += "- " + skill + "\n"
            st.markdown(s)

        st.header("–ö–∞—Ä—Ç–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π")
        knk_df_short = knk_df[knk_df.columns[3:-1]]
        main_comps = [item.name for item in full_char_list]
        for i in range(len(main_comps)):
            try:
                id_comp = df_id.query(f"–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è == '{main_comps[i].strip()}'").iloc[
                    0
                ]["ID"]
                id_comp = f" | –ö–æ–¥ {id_comp}"
            except Exception:
                id_comp = ""
            with st.expander(main_comps[i] + id_comp):
                index_start = knk_df_short[
                    knk_df_short["–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è"] == main_comps[i]
                ].index[0]
                index_end = index_start
                while index_end < knk_df_short.shape[0] - 1:
                    index_end += 1
                    if len(knk_df_short.loc[index_end]["–û—Å–Ω–æ–≤–Ω–∞—è –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è"]) > 0:
                        break
                if index_end == knk_df_short.shape[0] - 1:
                    index_end += 1
                knk_df_short_selected = knk_df_short.loc[index_start : index_end - 1][
                    knk_df_short.columns[1:]
                ].reset_index(drop=True)
                ids = []
                for comp in knk_df_short_selected["–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è"].values:
                    try:
                        id_comp = df_id.query(f"–ö–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è == '{comp.strip()}'").iloc[
                            0
                        ]["ID"]
                    except Exception:
                        id_comp = ""
                    ids.append(id_comp)
                knk_df_short_selected.index = ids
                st.markdown(
                    knk_df_short_selected.to_html(escape=False), unsafe_allow_html=True
                )

        st.header("–ù–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã—ã")
        st.dataframe(new_df)
